{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82bca5de",
   "metadata": {},
   "source": [
    "# Belief propagation for quantum LDPC codes, non binary belief propagation\n",
    "\n",
    "In this notebook we finally get to stack classical methods so they could be used to correct quantum errors.\n",
    "\n",
    "We will need the terminology we developed in the [linear algebra notebook](./linearAlgebra.ipynb), specifically, that there is an isomorphism between Pauli errors and binary vector-pairs:\n",
    "$$P \\rightarrow (P_z,P_x)$$\n",
    "\n",
    "Then we observe that if we have matrices $H_x$ and $H_z$ as described in the [stabilizer codes and their constructions](./Stabilizer%20LDPC%20codes.ipynb), and define \n",
    "$$H = (H_z|H_x)$$\n",
    "Which in numpy would be:\n",
    "```python\n",
    "H = np.hstack(H_z,H_x)\n",
    "``` \n",
    "Then the syndrome of $P$ is defined as:\n",
    "$$H_z \\cdot P_x^T + H_x \\cdot P_z^T$$\n",
    "(note that the $X$ generator matrix detects the $Z$ component of $P$ and the $Z$ generator matrix detects the $X$ component of $P$).\n",
    "\n",
    "This gives us a nice way to reduce the problem of decoding Pauli errors into two independent decoders, one defined by the $H_z$ matrix (which is fed $H_z \\cdot P_x^T$), and one defined by the $H_x$ matrix (which is fed $H_x \\cdot P_z^T$).\n",
    "\n",
    "We get two (binary) error vectors $E_z$ and $E_x$, and combine them back to a Pauli error using:\n",
    "$$(E_z,E_x) \\rightarrow \\tilde{P} $$\n",
    "\n",
    "This works to some extent, but does not take into account any correlation between $x$ and $z$ errors, which we will cover later.\n",
    "\n",
    "\n",
    "In the classical case, where we have a codeword $\\vec{c}$ and an error $\\vec{e}$ the decoder output could be one of the following:\n",
    "\n",
    "1. A decoder failure. This is where the decoder is unable to recover $\\vec{c}$ (or equivalently, $\\vec{e}$), and is aware that it failed (by calculating $H\\cdot \\vec{c'} \\neq \\vec{0}$)\n",
    "\n",
    "2. Decoder error. This is where the decoder beleives it found a solution, $\\vec{c}$ (or equivalently, $\\vec{e}$), where $H\\cdot \\vec{c'} = \\vec{0}$, however, $\\vec{c}\\neq \\vec{c'}$.\n",
    "\n",
    "3. Decoder success. This is where the right solution was found.\n",
    "\n",
    "Of the above three options, 3. is most desirable and 2. is most dangereous, and sometimes reffered to as false packet arrival (FPA) or silent data corruption (SDC).\n",
    "\n",
    "\n",
    "In [High-threshold and low-overhead fault-tolerant quantum memory](https://arxiv.org/abs/2308.07915)\n",
    "A logical error is declared if $E$ and $E^*$ have the same syndrome, but they differ by a non identity logical operator.\n",
    "\n",
    "From [Classical product code constructions for quantum Calderbank-Shor-Steane codes](https://quantum-journal.org/papers/q-2024-07-22-1420/pdf/)\n",
    "\n",
    "We have two binary matrices, $H^Z$ which defines the $Z$ generators, and $H^X$, which defines the $X$ generators. \n",
    "\n",
    "Now, any Pauli operator $P$ defined by $(v^X,v^Z)$ that's made of just Xs (in some, not necessarily all indices) will commute with all the X generators of the code. \n",
    "\n",
    "It may, however, not commute with the Z generators of the code. This happens exactly when the number of overlapping indices between the where that operator has an X and (at least one of) a Z generator is odd, namely when:\n",
    "$$H^X \\cdot v^Z \\neq 0 \\ \\ \\ (modulu \\ 2) $$\n",
    "\n",
    "However, whenever we have  \n",
    "$$H^X \\cdot v^Z = 0 \\ \\ \\ (modulu \\ 2) $$\n",
    "There are two options:\n",
    "\n",
    "1. $v^Z$ either is a valid stabilizer, or a multiplication of a few of them (addition over $F(2)$) meaning, $v^Z \\in span( (H^Z)^T )$\n",
    "2. $v^Z$ is not in the stabilizer group of the code, namely: $v^Z \\notin span( (H^Z)^T )$, in which it is a logical operator.\n",
    "\n",
    "In the case that $v^Z \\notin span( (H^Z)^T )$ and still $H^X \\cdot v^Z = 0 \\ \\ \\ (modulu \\ 2) $, we say that $v^Z$ is a logical error.\n",
    "\n",
    "We can check whether $v^Z$ is in $span((H^Z)^T)$ by appending it to $((H^Z)^T$ and using Gaussian elimination (assuming full rank to begin with).\n",
    "\n",
    "From the paper:\n",
    "\n",
    "\"\"\n",
    "\n",
    "For quantum CSS codes, one can distinguish different kinds of code minimum distance which we refer to as the pure distance $δ$ and the code distance $d$. The pure distances for X and Z errors are given, respectively, by \n",
    "$$\\delta^x := min\\{|v^x| : H^z \\cdot v^x = 0, v^x \\neq 0\\}$$\n",
    "$$\\delta^z := min\\{|v^z| : H^x \\cdot v^z = 0, v^z \\neq 0\\}$$\n",
    "\n",
    "and we simply call \n",
    "$$\\delta := min(\\delta^x, \\delta^z)$$\n",
    "\n",
    "the pure distance. By contrast, the code distances for X and Z errors are obtained by considering only errors patterns that do not leave the code-subspace invariant and thus do result in a logical error:\n",
    "$$d^x := min \\{|v^x| : H^z v^x = 0, v^x \\in span((H^x)^T)\\}$$\n",
    "$$d^z := min \\{|v^z| : H^x v^z = 0, v^z \\in span((H^z)^T)\\}$$\n",
    "\n",
    "We call $d := min(d^x, d^z)$ the code distance. Note that we always have $d ≥ δ$ and $d$ can be significantly larger than $δ$ in certain cases.\n",
    "\n",
    "\n",
    "\"\"\n",
    "\n",
    "\n",
    "Belief propagation generally works on factor graphs. In our context, we have a set of nodes that correspond to qubits, $V$, and another set of nodes that correspond to checks (factors in factor graph terminoplogy) $C$.\n",
    "\n",
    "We will also have a set of edges $E$, that will connect nodes in $V$ to checks in $C$ (but not checks to checks or qubit nodes to qubit nodes). The set of edges, in our context, is given either by a parity check matrix, or a set of stabilizer generators.\n",
    "When two checks $c,c'$ are both connected to $q,q'$, we will have a 4-cycle: $(q,c), (c,q'), (q',c'), (c',q)$.  \n",
    "\n",
    "\n",
    "## Quaternary BP\n",
    "The [algebra](/notebooks/linearAlgebra.ipynb) we covered includes handling of the case where we use the quaternary parity matrix $H$, and multiply it with the error vector $e$. Actually it's somewhat more elaborate than that, we start with a list of generators of the form $IIIZZ...$ ($Z$ generator) and $XXI...$ (an $X$ generator) and map them into $GF(4)$ vectors using:\n",
    "$$I \\rightarrow 0$$\n",
    "$$X \\rightarrow 1$$\n",
    "$$Y \\rightarrow \\bar{\\omega}$$\n",
    "$$Z \\rightarrow \\omega$$\n",
    "\n",
    "Then we can stack them as a matrix (which we can denote as $H$). By abuse of notation, we can talk about the elements of the matrix being $I,Z,X,Y$ instead of $0,1,\\omega, \\bar{\\omega}$.\n",
    "\n",
    "Then we have a Pauli error $E$, which we can map to a $GF(4)$ vector, $e$, in the same way. So remembering that multiplication in the Pauli group maps to $GF(4)$ addition, and that we want (!) the the equation:\n",
    "\n",
    "$$s[i] = H\\odot e[i] = (H[i,0] \\oplus e[0]) \\odot (H[i,1] \\oplus e[1]) ... \\odot (H[i,n-1] \\oplus e[n-1])$$\n",
    "\n",
    "To say $0$ if $E$ commutes with the $i'th$ stabilizer, and $1$ if it anticommutes, so we desinged it [in the algebra notebook](/notebooks/linearAlgebra.ipynb) to give us just that.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element: 0, MSB: 0, LSB: 0, Trace: 0\n",
      "Element: 1, MSB: 0, LSB: 1, Trace: 0\n",
      "Element: 2, MSB: 1, LSB: 0, Trace: 1\n",
      "Element: 3, MSB: 1, LSB: 1, Trace: 1\n",
      "Element: 0, value 0, Bar: 0\n",
      "0\n",
      "Element: 1, value 1, Bar: 1\n",
      "1\n",
      "Element: 2, value 2, Bar: 2\n",
      "ω\n",
      "Element: 3, value 3, Bar: 3\n",
      "(ω + 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c07b71cd",
   "metadata": {},
   "source": [
    "We now have most of the components to understand how BP over $GF(4)$ would look like.\n",
    "\n",
    "Let's start with some minmal non trivial parity matrix:\n",
    "\n",
    "$$H = \n",
    "\\begin{bmatrix}\n",
    "X & X & I\\\\\n",
    "Z & Z & Z\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Or in $GF(4)$ notation:\n",
    "\n",
    "$$H = \n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 0\\\\\n",
    "\\omega & \\omega & \\omega\\\\\n",
    "\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Let's look at a check node, that corresponds to the first row in $H$\n",
    "And an error\n",
    "$$E = (X,I,I) \\rightarrow (1,0,0)$$\n",
    "That yields:\n",
    "$$s[0] = Tr(H[0,:] \\cdot E^T) = Tr(1 \\cdot 1 + 1\\cdot 0 + 0\\cdot 0) = Tr(1) = 0$$\n",
    "$$s[1] = Tr(H[1,:] \\cdot E^T) = Tr(\\omega \\cdot 1 + \\omega\\cdot 0 + \\omega\\cdot 0) = Tr(\\omega + 0 + 0) = Tr(\\omega) = 1$$\n",
    "\n",
    "And we are trying to find $E = (E_0,E_1,E2)$ with the same syndrome.\n",
    "\n",
    "There are three variable nodes (corresponding to three columns of H, or three coordinates of $E$), and two check nodes.\n",
    "The $E_i$ are variables, which we are trying to solve, and at a given moment, we estimate $E_i$ to be $I$ with probability $q_i^I$, $X$ with probability $q_i^X$, $Z$ with probability $q_i^Z$ and $Y$ with probability $q_i^Y$ (so their sum, $\\sum_{_{W\\in\\{I,X,Y,Z\\}}}q_i^W$ is $1$).\n",
    "\n",
    "The variable nodes $E_i$ communicate these probabilities to each check node $C_j$ (not exactly, there are two subtlties here, but for now let's say to each check nodes).\n",
    "\n",
    "At check node $C_0$ we are trying to assign confidence (probability, belief) in every one of the following equations:\n",
    "\n",
    "Response to $E_0$ will be determined by:\n",
    "$$Tr((1 \\cdot E_1) + (1 \\cdot E_2)) = s_0 = 0$$\n",
    "\n",
    "Since $E_1$ and $E_2$ can be something from $\\{I,X,Y,Z\\}$, the above equation represents the following $4\\times4$ possible solutions:\n",
    "\n",
    "$$(1\\cdot 0) + (Y \\oplus I) = s_1$$\n",
    "\n",
    "$$(X\\oplus I) \\odot (Y \\oplus X) = s_1$$\n",
    "\n",
    "$$(X\\oplus I) \\odot (Y \\oplus Y) = s_1$$\n",
    "\n",
    "$$(X\\oplus I) \\odot (Y \\oplus Z) = s_1$$\n",
    "\n",
    "$$(X\\oplus X) \\odot (Y \\oplus I) = s_1$$\n",
    "\n",
    "$$(X\\oplus X) \\odot (Y \\oplus X) = s_1$$\n",
    "\n",
    "$$(X\\oplus X) \\odot (Y \\oplus Y) = s_1$$\n",
    "\n",
    "$$(X\\oplus X) \\odot (Y \\oplus Z) = s_1$$\n",
    "\n",
    "$$(X\\oplus Y) \\odot (Y \\oplus I) = s_1$$\n",
    "\n",
    "$$(X\\oplus Y) \\odot (Y \\oplus X) = s_1$$\n",
    "$$(X\\oplus Y) \\odot (Y \\oplus Z) = s_1$$\n",
    "\n",
    "$$(X\\oplus Y) \\odot (Y \\oplus Z) = s_1$$\n",
    "$$(X\\oplus Y) \\odot (Y \\oplus I) = s_1$$\n",
    "\n",
    "$$(X\\oplus Z) \\odot (Y \\oplus X) = s_1$$\n",
    "\n",
    "$$(X\\oplus Z) \\odot (Y \\oplus Y) = s_1$$\n",
    "\n",
    "$$(X\\oplus Z) \\odot (Y \\oplus Z) = s_1$$\n",
    "\n",
    "\n",
    "References:\n",
    "1. Degenerate Quantum LDPC Codes With Good Finite Length Performance https://arxiv.org/pdf/1904.02703\n",
    "2. Decoding Across the Quantum LDPC Code Landscape https://arxiv.org/pdf/2005.07016\n",
    "3. Quantum Kronecker sum-product low-density parity-check codes with finite rate https://link.aps.org/accepted/10.1103/PhysRevA.88.012311\n",
    "4. BP+OSD code https://github.com/quantumgizmos/bp_osd\n",
    "5. High-threshold and low-overhead fault-tolerant quantum memory\n",
    "6. [On the iterative decoding of sparse quantum codes](https://arxiv.org/abs/0801.1241)\n",
    "7. [Refined Belief Propagation Decoding of Sparse-Graph Quantum Codes](https://arxiv.org/abs/2002.06502)\n",
    "8. [Stabilizer Codes and Quantum Error Correction](https://arxiv.org/abs/quant-ph/9705052)\n",
    "\n",
    "\n",
    "Follow up that is not covered in this notebook yet:\n",
    "1. Decoding Quantum Tanner \n",
    "2. Loopy Belief Propagation: Convergence and Effects of Message Errors\n",
    "3. Probabilistic Graphical Models: A Concise Tutorial https://arxiv.org/pdf/2507.17116\n",
    "4. Improved belief propagation is sufficient for real-time decoding of quantum memory https://arxiv.org/pdf/2506.01779\n",
    "\n",
    "\n",
    "Plan for this workbook:\n",
    "\n",
    "1.\tRun bp+osd with a single code and parameters from the Degenerate Quantum LDPC Codes With Good Finite Length\n",
    "Performance. If possible, add a code from Improved belief propagation is sufficient for real-time decoding of quantum memory (which is taken from here https://link.aps.org/accepted/10.1103/PhysRevA.88.012311), and same for a single code from Decoding Across the Quantum LDPC Code Landscape\n",
    "2.\tSet the number of iterations to 0, 1, 10, 20, 100, 1000, 10000 and plot graphs. Is there a difference ?\n",
    "3.\tSo reading into 2005.07016, the conclusion is that you run X type error solely, then maybe if you want you can simulate Z type errors solely, but in any case you restrict yourself to hx or hz but not both.\n",
    "4.\tStart with the codes in here Degenerate Quantum LDPC Codes With Good Finite Length Performance\n",
    "a.\tA1\n",
    "b.\tB1 (if possible)\n",
    "c.\tC1 (if possible)\n",
    "d.\tMaybe D1 if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ef9593",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BpOsdDecoder' from 'ldpc' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mldpc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BpOsdDecoder\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mldpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcodes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rep_code\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbposd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhgp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hgp\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BpOsdDecoder' from 'ldpc' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ldpc import BpOsdDecoder\n",
    "from ldpc.codes import rep_code\n",
    "from bposd.hgp import hgp\n",
    "from qecc.polynomialCodes import A1_HX, A1_HZ, A2_HX, A2_HZ, A3_HX, A3_HZ, A4_HX, A4_HZ, A5_HX, A5_HZ,  A6_HX, A6_HZ, codes\n",
    "from bposd.css import css_code\n",
    "from scipy.linalg import lu\n",
    "import matplotlib.pyplot as plt\n",
    "from qecc import funWithMatrices\n",
    "import numpy as np\n",
    "seed = 7134066\n",
    "localRandom = np.random.RandomState(seed)\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#a = data['hx']\n",
    "\n",
    "# The codes from P&K don't have full rank.\n",
    "# for c in codes.keys():\n",
    "#     print(codes[c].shape)\n",
    "#     _,_,rank = funWithMatrices.binaryGaussianEliminationOnRows(copy.copy(codes[c].astype(np.bool)))\n",
    "#     print(f\"My code says the rank is {rank}\")\n",
    "    \n",
    "c = css_code(hx = A1_HX, hz = A1_HZ)    \n",
    "c.test()\n",
    "print(A2_HZ.shape)\n",
    "print(A2_HX.shape)\n",
    "254-28\n",
    "254-127\n",
    "_,_,rank = funWithMatrices.binaryGaussianEliminationOnRows(copy.copy(A1_HX.astype(np.bool)))\n",
    "print(rank)\n",
    "254-113\n",
    "plt.matshow(A2_HX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb40715",
   "metadata": {},
   "source": [
    "So how do we evaluate a code ?\n",
    "1. We'll load a matrix which will be either the $H^Z$ or $H^X$ matrix of the code  (for now we'll focus on X or Z errors only).\n",
    "2. We'll define a range of error probabilities to test the code over.\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#rangeFromDecodingAcrossTheQuantumLDPCCodeLandscape = [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]\n",
    "\n",
    "#rangeFromDecodingAcrossTheQuantumLDPCCodeLandscape = rangeFromDecodingAcrossTheQuantumLDPCCodeLandscape\n",
    "#rangeFromImprovedBeliefPropagationIsSufficientForRealTimeDecodingOfQuantumMemory = [0.001,0.002, 0.003, 0.004,0.005,0.006,0.007,0.008,0.009] \n",
    "#rangeFromImprovedBeliefPropagationIsSufficientForRealTimeDecodingOfQuantumMemory = rangeFromImprovedBeliefPropagationIsSufficientForRealTimeDecodingOfQuantumMemory\n",
    "totalRange = np.linspace(0.0003, 0.1, 50)#rangeFromImprovedBeliefPropagationIsSufficientForRealTimeDecodingOfQuantumMemory + rangeFromDecodingAcrossTheQuantumLDPCCodeLandscape \n",
    "totalRange = [float(i) for i in totalRange]\n",
    "\n",
    "numberOfIterations = [0,1,10,100,1000,10000]#,100,1000]\n",
    "\n",
    "marker = 0\n",
    "numberOfShots=100\n",
    "berDictionary = {}\n",
    "for iters in range(len(numberOfIterations)):\n",
    "    berDictionary[f\"Z_decode_ber_{numberOfIterations[iters]}_iterations\"] = np.zeros(len(totalRange))\n",
    "    berDictionary[f\"X_decode_ber_{numberOfIterations[iters]}_iterations\"] = np.zeros(len(totalRange))\n",
    "    phyErrors = np.zeros(len(totalRange))\n",
    "    k = 0\n",
    "    for p_error in totalRange:\n",
    "        bpdZ=BpOsdDecoder(A1.hz,#the parity check matrix\n",
    "        error_rate=p_error,\n",
    "        channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "        max_iter=numberOfIterations[iters], #the maximum number of iterations for BP)\n",
    "        bp_method=\"ms\",\n",
    "        ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "        osd_method=\"osd0\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "        osd_order=0 #the osd search depth\n",
    "        )   \n",
    "        bpdX=BpOsdDecoder(A1.hx,#the parity check matrix\n",
    "        error_rate=p_error,\n",
    "        channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "        max_iter=numberOfIterations[iters], #the maximum number of iterations for BP)\n",
    "        bp_method=\"ms\",\n",
    "        ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "        osd_method=\"osd0\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "        osd_order=0 #the osd search depth\n",
    "        )\n",
    "        print(f\"Error Rate: {p_error}\")\n",
    "        xLogicalErrorCount = 0\n",
    "        zLogicalErrorCount = 0\n",
    "        for i in range(numberOfShots):\n",
    "            error = localRandom.choice([0,1], size=code.N, replace=True, p=[1 - p_error, p_error])\n",
    "            phyErrors[k]+=np.sum(error)\n",
    "            syndrome=A1.hx@error %2\n",
    "            bpdZ.decode(syndrome)\n",
    "            residual_error = (bpdZ.osdw_decoding+error) % 2\n",
    "            #Decoding is successful if the residual error commutes with the logical operators\n",
    "            if (A1.lz@residual_error%2).any():\n",
    "                zLogicalErrorCount+=1\n",
    "            bpdX.decode(syndrome)\n",
    "            residual_error = (bpdX.osdw_decoding+error) % 2\n",
    "            #Decoding is successful if the residual error commutes with the logical operators\n",
    "            if (A1.lx@residual_error%2).any():\n",
    "                xLogicalErrorCount+=1\n",
    "        print(f\"Logical Errors: {xLogicalErrorCount}\\n\")\n",
    "        print(f\"Logical Errors: {zLogicalErrorCount}\\n\")\n",
    "        berDictionary[f\"X_decode_ber_{numberOfIterations[iters]}_iterations\"][k]=xLogicalErrorCount\n",
    "        berDictionary[f\"Z_decode_ber_{numberOfIterations[iters]}_iterations\"][k]=zLogicalErrorCount\n",
    "        k +=1\n",
    "    marker = marker +1\n",
    "    \n",
    "\n",
    "\n",
    "markers = ['-', '-o', '-^', '-+', '-*', '-x', '-s', '-d']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figX, axX = plt.subplots(1, 1, layout='constrained')\n",
    "axX.set(title='A1.hX Code: BP+OSD Decoding Performance', xlabel='Physical Error Rate', ylabel='Rate of logical errors.')\n",
    "\n",
    "for iters in range(len(numberOfIterations)):\n",
    "    axX.loglog(totalRange[10:], berDictionary[f\"X_decode_ber_{numberOfIterations[iters]}_iterations\"][10:]/numberOfShots, markers[iters], label = f\"BP+OSD Decoding for A1.hz with {numberOfIterations[iters]} BP iterations.\")    \n",
    "    #ax1.loglog(totalRange, phyErrors/(numberOfShots * code.N), '-', label = 'Physical Errors, actual (sanity check).')\n",
    "# #ax1.axvspan(0, 0.1, facecolor='lightblue', alpha=0.3, 'Region tested by IBM')   # Left side background\n",
    "# #ax1.axvspan(0.1, 0.5, facecolor='lightgreen', alpha=0.3, 'Region by Panteleev and Kalachev') # Right side background\n",
    "axX.legend()\n",
    "axX.grid()\n",
    "axX.grid(which=\"minor\", color=\"0.9\")\n",
    "\n",
    "\n",
    "figZ, axZ = plt.subplots(1, 1, layout='constrained')\n",
    "axZ.set(title='A1.hZ Code: BP+OSD Decoding Performance', xlabel='Physical Error Rate', ylabel='Rate of logical errors.')\n",
    "\n",
    "for iters in range(len(numberOfIterations)):\n",
    "    axZ.loglog(totalRange, berDictionary[f\"Z_decode_ber_{numberOfIterations[iters]}_iterations\"]/numberOfShots, markers[iters], label = f\"BP+OSD Decoding for A1.hz with {numberOfIterations[iters]} BP iterations.\")    \n",
    "    #ax1.loglog(totalRange, phyErrors/(numberOfShots * code.N), '-', label = 'Physical Errors, actual (sanity check).')\n",
    "# #ax1.axvspan(0, 0.1, facecolor='lightblue', alpha=0.3, 'Region tested by IBM')   # Left side background\n",
    "# #ax1.axvspan(0.1, 0.5, facecolor='lightgreen', alpha=0.3, 'Region by Panteleev and Kalachev') # Right side background\n",
    "axZ.legend()\n",
    "axZ.grid()\n",
    "axZ.grid(which=\"minor\", color=\"0.9\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osd1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
