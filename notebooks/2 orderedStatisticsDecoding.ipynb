{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d87b773",
   "metadata": {},
   "source": [
    "# OSD decoding\n",
    "\n",
    "For the purposes of this notebook, the ideas presented here are from:\n",
    "\n",
    "[Degenerate Quantum LDPC Codes With Good Finite Length Performance](https://arxiv.org/pdf/1904.02703).\n",
    "\n",
    "[Tour de gross: A modular quantum computer based on bivariate bicycle codes](https://arxiv.org/pdf/2506.03094)\n",
    "\n",
    "[Decoding Across the Quantum LDPC Code Landscape](https://arxiv.org/pdf/2005.07016)\n",
    " some code of which is [here](https://github.com/quantumgizmos/bp_osd).\n",
    "\n",
    "[Improved belief propagation is sufficient for real-time decoding of quantum memory](https://arxiv.org/pdf/2506.01779) which introduces relay BP, with some code [here](https://github.com/FranciscoRevson/relay-BP-IBM).\n",
    "\n",
    "[Fully Parallelized BP Decoding for Quantum LDPC Codes Can Outperform BP-OSD](https://arxiv.org/html/2507.00254v2)\n",
    "\n",
    "\n",
    "\n",
    "Fix $n$ and a linear binary code, $\\mathcal{C}$ of dimension $k$. So $\\mathcal{C} \\subset F^n_2$ such that $\\mathcal{C} \\cong F_2^k$ and in particular has $2^k$ elements. \n",
    "Choose a generator matrix $G$, meaning a matrix which row space spans the code, and a parity matrix $H$, namely a matrix which kernel is the code.\n",
    "By definition of the parity matrix, if $c\\in \\mathcal{C}$ then $H \\cdot c = \\vec{0}$. Generally we call the resulting vector $H \\cdot w = s$ the syndrome. \n",
    "\n",
    "Excersize:\n",
    "Show that if $v,w$ have the same syndrome, then they differ by a codeword.\n",
    "\n",
    "For a set of indices, $I \\subset {1,..n} = [n]$, we say that $I$ is an information set for the code $\\mathcal{C}$, if:\n",
    "\n",
    "$$C_I:=\\{c_{i\\in I} : c\\in \\mathcal{C}\\} = F_2^k$$\n",
    "\n",
    "Meaning, that when we restrict each $n$ dimensional codeword $c$ to the set of indices in $I$, and go over all codewords in $\\mathcal{C}$, we get the set $F_2^k$, and in fact we get an isomorphism of vector spaces between $\\mathcal{C}$ and $F_2^k$ which is a projection.\n",
    "\n",
    "Excersize:\n",
    "1.  Show that for an information set $I$, the map: $P_I: \\mathcal{C} \\rightarrow F_2^k$ defined by: $P_I(c) = P_I(c_{i\\in [n]}) = c_{i\\in I}$ is linear, one to one and onto, i.e., it is an isomorphism of vector spaces.\n",
    "2. Conclude that if $P_I(c) = P_I(c')$ then $c=c'$\n",
    "\n",
    "Every pair of information set and syndrome for the code $\\mathcal{C}$ and $H$ gives us an encoding $E(x) = E(s,I,x):F_2^k \\rightarrow F^n_2$: first, the bijection $P_I$ picks one representative of $\\mathcal{C}$ - the one that agrees with x over all indices in $I$. Then the rest of the values for indices outside $I$ are uniqely determined by the syndrome.\n",
    "\n",
    "\n",
    "Now let's assume we have a word $c' = c + e$, and we want to recover $c$. We also have an estimate $\\hat{e}$ of $e$, but we find that $H \\cdot \\hat{e} \\neq H \\cdot e$, so we have evidence that $\\hat{e} \\neq e$. \n",
    "If we knoew of an information set $I$ such that $e_I = \\hat{e}_I$, i.e., they agree on the set $I$, then the encoding $E(s = H\\cdot e,I,\\hat{e})$ would find us the right $e$.\n",
    "\n",
    "Suppose further that our estimate of $\\hat{e}$ was cooked from probabilities $p_i$, where $p_i$ is the probability of the error $e$ being $1$ at index $i$, i.e.:\n",
    "$$p_i = P(e_i = 1)$$\n",
    "And we decide that we estimate $\\hat{e}$ using: $e_i = 1$ if $p_i >= 1/2$ and 0 otherwise.\n",
    "\n",
    "This is why we introduce the notion of a reliability $\\rho$ of an index $i$:\n",
    "$$\\rho_i = P(\\hat{e}_i = e_i)$$\n",
    "Which using our estimation rule means \n",
    "$$\\rho_i = max(p_i, 1-p_i)$$\n",
    "(since if $p_i$ is the bigger one, we decided $\\hat{e_i}$ = 1, and otherwise, i.e. $1-p_i$  is bigger, and we decided $\\hat{e_i}=0$ but either way we are as certain as $max(p_i, 1-p_i)$). \n",
    "\n",
    "\n",
    "\n",
    "BIN:\n",
    "\n",
    "\n",
    "\n",
    "So suppose we knew, that the error part of $x = c + e$ occures outside some information set $J$, then we could find out the error precisely usining $E(s,J,\\vec{0})$ for $s=H \\cdot (c+e) = H \\cdot e$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 26\n",
      "True \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qecc.polynomialCodes import codes, A1_HX, A1_HZ, A2_HX, A2_HZ, A3_HX, A3_HZ, A4_HX, A4_HZ, A5_HX, A5_HZ,  A6_HX, A6_HZ\n",
    "seed = 777\n",
    "localRandom = np.random.RandomState(seed)\n",
    "from qecc import funWithMatrices, logicals\n",
    "import scipy\n",
    "import copy\n",
    "\n",
    "from qecc.osd import osdDecoder\n",
    "H_X = A1_HX.astype(np.int32)\n",
    "H_Z = A1_HZ.astype(np.int32)\n",
    "L_X, L_Z = logicals.computeLogicals(H_X, H_Z)\n",
    "\n",
    "# In the following we simulate errors, and set the reliability vector true to where errors occurred.\n",
    "probabilityOfError = 0.1\n",
    "# Create an error pattern\n",
    "error = np.random.choice([0,1], size=(H_X.shape[1],), p=[1-probabilityOfError, probabilityOfError]).astype(np.int32)\n",
    "print( f\"Number of errors: {np.count_nonzero(error)}\")\n",
    "# Calculate the syndrome\n",
    "syndrome = H_X @ error %2\n",
    "coordinateReliabilities = error * probabilityOfError + (1-error)*(1-probabilityOfError) #np.ones(code.shape[1]) * probabilityOfError\n",
    "solution, reliability = osdDecoder(H_X, syndrome, coordinateReliabilities)\n",
    "print(f\"{np.all(solution  == error)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce4524",
   "metadata": {},
   "source": [
    "From [Stabilizer Codes and Quantum Error Correction](https://arxiv.org/pdf/quant-ph/9705052)\n",
    "Now, there generally are many elements of G that commute with everything\n",
    " in S but are not actually in S. The set of elements in G that commute with all\n",
    " of S is defined as the centralizer C(S) of S in G. Because of the properties of S\n",
    " and G, the centralizer is actually equal to the normalizer N(S) of S in G, which\n",
    " is defined as the set of elements of G that fix S under conjugation. To see this,\n",
    " note that for any A ∈ G, M ∈ S,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Next we want to check if the decoder accidentally spitted out a logical operator, also known as decoder error, scilent data corription, false packet arrival etc.:\n",
    "# We will use Qiskit to check for logical errors https://qiskit-community.github.io/qiskit-qec/tutorials/QEC_Framework_IEEE_2022.html\n",
    "# We could also use  Logical operators of quantum codes (https://journals.aps.org/pra/pdf/10.1103/PhysRevA.79.062322) to write something from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe632a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m probabilityOfError \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create an error pattern\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], size\u001b[38;5;241m=\u001b[39m(\u001b[43mcode\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), p\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mprobabilityOfError, probabilityOfError])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of errors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mcount_nonzero(error)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate the syndrome\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# If however we set the reliability vector to be uniform, we have decoding failure, even at low error rates.\n",
    "probabilityOfError = 0.01\n",
    "# Create an error pattern\n",
    "error = np.random.choice([0,1], size=(code.shape[1],), p=[1-probabilityOfError, probabilityOfError]).astype(np.int32)\n",
    "print( f\"Number of errors: {np.count_nonzero(error)}\")\n",
    "# Calculate the syndrome\n",
    "syndrome = code @ error %2\n",
    "coordinateReliabilities = np.ones(code.shape[1]) * probabilityOfError\n",
    "solution, reliability = osdDecoder(code, syndrome, coordinateReliabilities)\n",
    "print(f\"{np.all(solution  == error)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74eb97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating for probability of error 0.001\n",
      "Logical error rate at probability of error 0.001 is 0.0\n",
      "Simulating for probability of error 0.012\n",
      "Logical error rate at probability of error 0.012 is 0.0\n",
      "Simulating for probability of error 0.023000000000000003\n",
      "Logical error rate at probability of error 0.023000000000000003 is 0.0\n",
      "Simulating for probability of error 0.034\n",
      "Logical error rate at probability of error 0.034 is 0.0\n",
      "Simulating for probability of error 0.045000000000000005\n",
      "Logical error rate at probability of error 0.045000000000000005 is 0.0\n",
      "Simulating for probability of error 0.05600000000000001\n",
      "Logical error rate at probability of error 0.05600000000000001 is 0.0\n",
      "Simulating for probability of error 0.067\n"
     ]
    }
   ],
   "source": [
    "# So the conclusion is that we need reliabilities that are as accurate as possible\n",
    "from qecc.memBP import decode\n",
    "from qecc.funWithMatrices import binaryGaussianEliminationOnRows\n",
    "from qecc.logicals import computeLogicals\n",
    "matrix, matrixInverse, rank = binaryGaussianEliminationOnRows(copy.copy(H_X))\n",
    "numberOfSamples = 20\n",
    "OSD_DECODE = False\n",
    "\n",
    "pError = np.linspace(0.001, 0.1, 10)\n",
    "logicalErrors = np.zeros(len(pError))\n",
    "ber = np.zeros(len(pError))\n",
    "for p in range(len(pError)):\n",
    "    probabilityOfError = pError[p]\n",
    "    print(f\"Simulating for probability of error {probabilityOfError}\")\n",
    "    for i in range(numberOfSamples):\n",
    "        error = np.random.choice([0,1], size=(H_X.shape[1],), p=[1-probabilityOfError, probabilityOfError]).astype(np.int32)\n",
    "        numberOfIterations = 50\n",
    "        coordinateReliabilities = np.ones(H_X.shape[1]) * probabilityOfError\n",
    "        initMarginals = np.ones(H_X.shape[1]) * np.log( (1 - probabilityOfError) / probabilityOfError )\n",
    "        errorVector, marginals, converged, iteration = decode(H_X, initMarginals = initMarginals, errorProbabilities= initMarginals, sigma = (H_X @ error %2), Gammas = None, maxIterations=numberOfIterations, logProbabilities = True)\n",
    "        #Count bit errors\n",
    "        ber[p]+= np.sum(np.where(errorVector  == error, 0, 1))\n",
    "        if OSD_DECODE:\n",
    "            if not np.all(errorVector  == error):\n",
    "                #print(f\"Attempting OSD decoding:\")\n",
    "                solution, reliability = osdDecoder(H_X, (H_X @ error %2), marginals)\n",
    "                #print(f\"Is the solution exact ? {np.all(solution  == error)} \")\n",
    "                #print(f\"What about the syndrome of the solution: {np.all((H_X @ solution %2) == (H_X @ error %2))} \")\n",
    "                #print(f\"With reliability {reliability}\")\n",
    "                # Check whether a logical error occurred\n",
    "                residualError = (error + solution) %2\n",
    "                if np.any(H_X @ residualError % 2) or np.any(L_X @ residualError % 2):\n",
    "                    #print(\"Logical error occurred!\")\n",
    "                    logicalErrors[p] += 1\n",
    "    print(f\"Logical error rate at probability of error {probabilityOfError} is {logicalErrors[p]/numberOfSamples}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "880bd124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149.  46.  64. 121.  99. 126.  46.  79.  85.  92.]\n"
     ]
    }
   ],
   "source": [
    "print(ber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c64309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(pError, ber, marker='o')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osd1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
